#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os, re, json, numpy as np, pandas as pd
from Bio import SeqIO
from tqdm import tqdm
import torch

PROJ = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
CSV_PATH = os.path.join(PROJ, "data", "filtered_abbind_single_mutations.csv")
FASTA_PATH = os.path.join(PROJ, "data", "wt_antibodies.fasta")
MAP_DIR = os.path.join(PROJ, "data", "residue_index_maps")
OUT_DIR = os.path.join(PROJ, "mutant_embeddings")
INDEX_OUT = os.path.join(PROJ, "data", "embedding_index.csv")
LOG_PATH = os.path.join(PROJ, "results", "embedding_log.jsonl")
os.makedirs(OUT_DIR, exist_ok=True); os.makedirs(os.path.join(PROJ, "results"), exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("ğŸš€ device:", device)

try:
    import esm
except ImportError:
    raise SystemExit("è¯·å…ˆå®‰è£… fair-esm: pip install fair-esm")

# è½½å…¥ ESM-1b
model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()
model.eval().to(device)
batch_converter = alphabet.get_batch_converter()

# å…è®¸æ’å…¥ç ï¼šH:Y100aF / L:D27bA / A:Q221A ç­‰ï¼ˆicode å¯æœ‰å¯æ— ï¼Œå¤§å°å†™çš†å¯ï¼‰
MUT_RE = re.compile(r"^([A-Za-z])\s*:\s*([A-Za-z])(\d+)([A-Za-z]?)([A-Za-z])$")
AA1 = set("ACDEFGHIKLMNPQRSTVWY")
MAX_LEN = 1022  # ä½ çš„ FASTA å·²ç»è¿‡æ»¤ >1022ï¼Œè¿™é‡Œåªæ˜¯åŒä¿é™©

def parse_mutation(mut):
    m = MUT_RE.match(mut.strip())
    if not m:
        raise ValueError(f"æ— æ³•è§£æçªå˜: {mut}")
    chain, wt, num, icode, mt = m.groups()
    wt, mt = wt.upper(), mt.upper()
    icode = icode.upper()
    if wt not in AA1 or mt not in AA1: raise ValueError(f"éæ ‡å‡†AA: {mut}")
    return chain.strip(), wt, int(num), icode, mt

def load_map(pdb, chain):
    p = os.path.join(MAP_DIR, f"{pdb}_{chain}.json")
    if not os.path.isfile(p): raise FileNotFoundError(f"ç¼ºæ˜ å°„: {p}")
    return json.load(open(p))  # é”® "num|icode", icodeä¸ºç©ºç”¨ ""

def embed_mean(seq):
    if len(seq) > MAX_LEN:
        raise RuntimeError(f"sequence too long after filter: {len(seq)}")
    data = [("s", seq)]
    _, _, toks = batch_converter(data); toks = toks.to(device)
    with torch.no_grad():
        out = model(toks, repr_layers=[33], return_contacts=False)
        rep = out["representations"][33][0, 1:1+len(seq), :]
    return rep.mean(0).cpu().numpy()

def log_err(**k):
    with open(LOG_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(k, ensure_ascii=False) + "\n")

# è½½å…¥æ•°æ®
df = pd.read_csv(CSV_PATH)
seqs = {r.id: str(r.seq).upper() for r in SeqIO.parse(FASTA_PATH, "fasta")}

ok = fail = 0
rows = []

for _, row in tqdm(df.dropna(subset=["#PDB","Mutation"]).iterrows(),
                   total=len(df.dropna(subset=["#PDB","Mutation"]))):
    pdb = str(row["#PDB"]).upper().strip()
    mut = str(row["Mutation"]).strip()
    try:
        chain, wt, num, icode, mt = parse_mutation(mut)
        fasta_id = f"{pdb}_{chain}"
        if fasta_id not in seqs:
            raise FileNotFoundError(f"FASTAç¼ºå°‘åºåˆ—: {fasta_id}")

        num2idx = load_map(pdb, chain)  # ä¾‹å¦‚ "100|A"ã€"487|"
        key = f"{num}|{icode}" if icode else f"{num}|"
        if key not in num2idx:
            # å®¹é”™ï¼šå¦‚æœå¸¦icodeæ²¡å‘½ä¸­ï¼Œå°è¯•ä¸å¸¦icodeé”®
            alt = f"{num}|"
            if alt in num2idx: key = alt
            else: raise KeyError(f"PDBç¼–å·ä¸å­˜åœ¨äºæ˜ å°„: {key}")

        idx = int(num2idx[key])
        wt_seq = seqs[fasta_id]
        if idx < 0 or idx >= len(wt_seq):
            raise IndexError(f"ç´¢å¼•è¶Šç•Œ idx={idx} len={len(wt_seq)}")
        if wt_seq[idx] != wt:
            raise ValueError(f"é‡ç”Ÿå‹ä¸åŒ¹é…: æœŸæœ› {wt}@{num}{icode or ''}, å®é™… {wt_seq[idx]}")

        mut_seq = wt_seq[:idx] + mt + wt_seq[idx+1:]
        if len(mut_seq) > MAX_LEN:
            raise RuntimeError(f"mut seq too long: {len(mut_seq)}")

        emb = embed_mean(mut_seq)
        out_name = f"{pdb}_{chain}_{wt}{num}{icode or ''}{mt}.npy"
        np.save(os.path.join(OUT_DIR, out_name), emb)
        rows.append({"pdb": pdb, "chain": chain, "mutation": mut,
                     "embedding_file": out_name, "length": len(mut_seq)})
        ok += 1
    except Exception as e:
        fail += 1
        log_err(pdb=pdb, mutation=mut, error=f"{type(e).__name__}: {e}")
        print(f"âš ï¸ {pdb}::{mut} å¤±è´¥: {type(e).__name__}: {e}")

pd.DataFrame(rows).to_csv(INDEX_OUT, index=False)
print(f"âœ… å®Œæˆï¼šæˆåŠŸ {ok} æ¡ï¼Œå¤±è´¥ {fail} æ¡")
print(f"ğŸ“„ ç´¢å¼•ï¼š{INDEX_OUT}")
print(f"ğŸ“‚ å‘é‡ï¼š{OUT_DIR}")
print(f"ğŸ“ æ—¥å¿—ï¼š{LOG_PATH}")
